# LLM-notes

LLM holistic understanding, theory, maths, re-usable code/notes :hugs:

Start with:
- Machine Learning t1p1
- Encoders Decoders (Vanilla) t1p2
- Auto-Encoders (Vanilla) t1p3
- Encoders Decoders (Attention) t1p4
- Neural Turing Machines t1p5
- Transformers t1p6
- Large Language Models


 Deep shit :
- Watch EVERYTHING (Andrej Karpathy) - https://www.youtube.com/@AndrejKarpathy/videos
- Practical ML papers (George Hotz) - https://www.youtube.com/watch?v=YrWEDOQQ8pw
- All you need for Attention (Lilan Weng) - https://lilianweng.github.io/posts/2018-06-24-attention/
- Seq2Seq (statquest) - https://www.youtube.com/watch?v=L8HKweZIOmg
- Variational AutoEncoders (Arxiv) - https://www.youtube.com/watch?v=9zKuYvjFFS8&t=303s
  