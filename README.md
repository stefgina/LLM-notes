need solid fundamentals:
- learn linear algebra (matrix operations, inversion/determinant, linear independence, eigenvalues/eigenvectors, norms/inner-products, decompositions)
- learn calculus (differential, integral, optimisation, cost functions, Taylor series, multivariate)
- code back-prop without auto-grad
- learn computational graphs
- code a simple auto-grad framework
- vectorisation/parallelisation

understand these, and then use the fucking PyTorch

## High Level:
- Machine Learning 
- Encoders Decoders (Vanilla) 
- Auto-Encoders (Vanilla) 
- Encoders Decoders (Attention) 
- Neural Turing Machines
- Transformers 
- Large Language Models


## Intuition:
- Seq2Seq (statquest) - https://www.youtube.com/watch?v=L8HKweZIOmg
- Variational AutoEncoders (Arxiv) - https://www.youtube.com/watch?v=9zKuYvjFFS8&t=303s


## Deep in the rabbit hole :
- Way of thinking ML papers (George Hotz) - https://www.youtube.com/watch?v=YrWEDOQQ8pw
- Attention (Lilan Weng) - https://lilianweng.github.io/posts/2018-06-24-attention/
- Watch EVERYTHING (Andrej Karpathy) - https://www.youtube.com/@AndrejKarpathy/videos

## Code:
  - seq2seq (bentrevett) - https://github.com/bentrevett/pytorch-seq2seq/tree/master